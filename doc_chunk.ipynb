{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1n497drerqUMM1SAieZgzGS8sxHvk8cFn",
      "authorship_tag": "ABX9TyOIPostGK1+uWs6BfB65Mft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabia340/LLM_project/blob/main/doc_chunk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8JczFnFMDNO",
        "outputId": "b37b07a3-9385-49bc-c63e-375123ce6cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx # install the python-docx module that provides the docx package\n",
        "from docx import Document # import the Document class from the docx package\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1JkK-ZyVzZq",
        "outputId": "582864f9-1c7a-4522-a871-017a146216ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def read_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "\n",
        "     #Extract text from each paragraph and combine into a single string\n",
        "    full_text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "    return full_text\n",
        "\n",
        "def chunk_text(text, chunk_size=200):\n",
        "    # Break the text into chunks of a specified size\n",
        "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/LLM_pdf/abstract-leaf.docx'\n",
        "\n",
        "# Read the document content\n",
        "document_text = read_docx(file_path)\n",
        "\n",
        "\n",
        "# Chunk the document content\n",
        "chunks = chunk_text(document_text, chunk_size=200)\n",
        "\n",
        "\n",
        "# Loop through each item in the list 'chunks'\n",
        "for i in range(len(chunks)):\n",
        "    # Get the chunk at the current index\n",
        "    chunk = chunks[i]\n",
        "\n",
        "    # Print the chunk number\n",
        "    print(\"Chunk {}:\".format(i + 1))\n",
        "\n",
        "    # Print the content of the current chunk\n",
        "    print(chunk)\n",
        "\n",
        "    # Print a separator line for readability\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3U3JiiWbKHX",
        "outputId": "b68fac62-98e4-4d55-8b83-5714fc117716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "Abstract:\n",
            "\n",
            "This study explores an image acquisition process for leaf recognition, focusing on venation patterns, monocot and dicot differentiation, and leaf shape analysis. We collected a diverse set \n",
            "----------------------------------------\n",
            "Chunk 2:\n",
            "of leaf images, ensuring high quality through controlled environmental conditions and consistent pre-processing steps, including noise reduction, segmentation, and normalization. The dataset, comprisi\n",
            "----------------------------------------\n",
            "Chunk 3:\n",
            "ng 3163 leaf images in .JPG format, was manually organized by class and utilized advanced deep learning models for comparative analysis. Our methodology involved data augmentation, feature extraction,\n",
            "----------------------------------------\n",
            "Chunk 4:\n",
            " and transfer learning.For comparative analysis, we applied the dataset to four deep learning models: VGG16, NasNetMobile, Inception V3, and MobileNet V2. These models were selected for their proven e\n",
            "----------------------------------------\n",
            "Chunk 5:\n",
            "fficacy in image recognition tasks. Our evaluation metrics focused on the accuracy of each model in recognizing leaf features. The VGG16 model achieved an accuracy of 94.64%, NasNetMobile 95.12%, and \n",
            "----------------------------------------\n",
            "Chunk 6:\n",
            "Inception V3 94.52%. MobileNet V2 outperformed the others, attaining an accuracy of 97.02%.\n",
            "These findings underscore the superior performance of MobileNet V2 in leaf recognition tasks, demonstrating \n",
            "----------------------------------------\n",
            "Chunk 7:\n",
            "its potential for high accuracy and efficiency. The implications of this research are significant for botanical studies and agricultural applications, where precise leaf identification can enhance pla\n",
            "----------------------------------------\n",
            "Chunk 8:\n",
            "nt classification, disease detection, and overall agricultural management.\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}